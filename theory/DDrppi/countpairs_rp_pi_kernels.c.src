// # -*- mode: c -*-
/* File: countpairs_rp_pi_kernels.c.src */
/*
  This file is a part of the Corrfunc package
  Copyright (C) 2015-- Manodeep Sinha (manodeep@gmail.com)
  License: MIT LICENSE. See LICENSE file under the top-level
  directory at https://github.com/manodeep/Corrfunc/
*/


#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <inttypes.h>

#include "function_precision.h"
#include "utils.h"

#include "weight_functions_DOUBLE.h"

#if defined(__AVX__)
#include "avx_calls.h"

static inline int countpairs_rp_pi_avx_intrinsics_DOUBLE(const int64_t N0, DOUBLE *x0, DOUBLE *y0, DOUBLE *z0, const weight_struct_DOUBLE *weights0,
                                                         const int64_t N1, DOUBLE *x1, DOUBLE *y1, DOUBLE *z1, const weight_struct_DOUBLE *weights1, const int same_cell, 
                                                         const DOUBLE sqr_rpmax, const DOUBLE sqr_rpmin, const int nbin,
                                                         const int npibin, const DOUBLE *rupp_sqr, const DOUBLE pimax,
                                                         const DOUBLE off_xwrap, const DOUBLE off_ywrap, const DOUBLE off_zwrap,
                                                         DOUBLE *src_rpavg, uint64_t *src_npairs,
                                                         DOUBLE *src_weightavg, const weight_method_t weight_method)
{
    if(N0 == 0 || N1 == 0) {
        return EXIT_SUCCESS;
    }

    if(src_npairs == NULL) {
        return EXIT_FAILURE;
    }
    
    const int32_t need_rpavg = src_rpavg != NULL;
    const int32_t need_weightavg = src_weightavg != NULL;
    
    const int64_t totnbins = (npibin+1)*(nbin+1);
    uint64_t npairs[totnbins];
    DOUBLE rpavg[totnbins], weightavg[totnbins];
    for(int64_t i=0;i<totnbins;i++) {
        npairs[i] = 0;
        if(need_rpavg) {
            rpavg[i] = ZERO;
        }
        if(need_weightavg){
            weightavg[i] = ZERO;
        }
    }


    AVX_FLOATS m_rupp_sqr[nbin];
    AVX_FLOATS m_kbin[nbin];
    for(int i=0;i<nbin;i++) {
        m_rupp_sqr[i] = AVX_SET_FLOAT(rupp_sqr[i]);
        m_kbin[i] = AVX_SET_FLOAT((DOUBLE) i);
    }

    const DOUBLE dpi = pimax/npibin;
    const DOUBLE inv_dpi = 1.0/dpi;
    
    // A copy whose pointers we can advance
    weight_struct_DOUBLE local_w0 = {.weights={NULL}, .num_weights=0}, 
                         local_w1 = {.weights={NULL}, .num_weights=0};
    pair_struct_DOUBLE pair = {.num_weights=0};
    avx_weight_func_t_DOUBLE avx_weight_func = NULL;
    weight_func_t_DOUBLE fallback_weight_func = NULL;
    if(need_weightavg){
        // Same particle list, new copy of num_weights pointers into that list
        local_w0 = *weights0;
        local_w1 = *weights1;

        pair.num_weights = local_w0.num_weights;

        avx_weight_func = get_avx_weight_func_by_method_DOUBLE(weight_method);
        fallback_weight_func = get_weight_func_by_method_DOUBLE(weight_method);
    }

    int64_t prev_j = 0, n_off = 0;    
    for(int64_t i=0;i<N0;i++) {
        const DOUBLE xpos = *x0++ + off_xwrap;
        const DOUBLE ypos = *y0++ + off_ywrap;
        const DOUBLE zpos = *z0++ + off_zwrap;
        for(int w = 0; w < pair.num_weights; w++){
            // local_w0.weights[w] is a pointer to a float in the particle list of weights,
            // just as x0 is a pointer into the list of x-positions.
            // The advancement of the local_w0.weights[w] pointer should always mirror x0.
            pair.weights0[w].a = AVX_SET_FLOAT(*(local_w0.weights[w])++);
        }

        int64_t j;
        if(same_cell == 1) {
            z1++; n_off++;
            j = i+1;
        } else {
            for(;prev_j<N1;prev_j++) {
                const DOUBLE dz = *z1 - zpos;
                if(dz > -pimax) break;
                z1++; n_off++;
            }
            if(prev_j == N1) {
                i = N0;
                break;
            }
            j = prev_j;
        }
        DOUBLE *localz1 = z1;
        DOUBLE *localx1 = x1 + n_off;
        DOUBLE *localy1 = y1 + n_off;
        for(int w = 0; w < local_w1.num_weights; w++){
            local_w1.weights[w] = weights1->weights[w] + n_off;
        }

        for(;j<=(N1 - AVX_NVEC);j+=AVX_NVEC) {
            const AVX_FLOATS m_xpos    = AVX_SET_FLOAT(xpos);
            const AVX_FLOATS m_ypos    = AVX_SET_FLOAT(ypos);
            const AVX_FLOATS m_zpos    = AVX_SET_FLOAT(zpos);
            
            union int8 {
                AVX_INTS m_ibin;
                int ibin[AVX_NVEC];
            };
            union int8 union_finalbin;
            union float8{
                AVX_FLOATS m_Dperp;
                DOUBLE Dperp[AVX_NVEC];
            };
            union float8 union_mDperp;

            
            const AVX_FLOATS m_x1 = AVX_LOAD_FLOATS_UNALIGNED(localx1);
            const AVX_FLOATS m_y1 = AVX_LOAD_FLOATS_UNALIGNED(localy1);
            const AVX_FLOATS m_z1 = AVX_LOAD_FLOATS_UNALIGNED(localz1);
            
            localx1 += AVX_NVEC;//this might actually exceed the allocated range but we will never dereference that
            localy1 += AVX_NVEC;
            localz1 += AVX_NVEC;
            
            for(int w = 0; w < pair.num_weights; w++){
                pair.weights1[w].a = AVX_LOAD_FLOATS_UNALIGNED(local_w1.weights[w]);
                local_w1.weights[w] += AVX_NVEC;
            }

            union float8_weights{
                AVX_FLOATS m_weights;
                DOUBLE weights[NVEC];
            };
            union float8_weights union_mweight;

            const AVX_FLOATS m_pimax = AVX_SET_FLOAT((DOUBLE) pimax);
            const AVX_FLOATS m_sqr_rpmax = m_rupp_sqr[nbin-1];
            const AVX_FLOATS m_sqr_rpmin = m_rupp_sqr[0];
            const AVX_FLOATS m_inv_dpi    = AVX_SET_FLOAT(inv_dpi);
            const AVX_FLOATS m_zero = AVX_SET_FLOAT(ZERO);
            const AVX_FLOATS m_npibin     = AVX_SET_FLOAT((DOUBLE) npibin);
            const AVX_FLOATS m_one    = AVX_SET_FLOAT((DOUBLE) 1);

            const AVX_FLOATS m_xdiff = AVX_SUBTRACT_FLOATS(m_x1, m_xpos);  //(x[j] - x0)
            const AVX_FLOATS m_ydiff = AVX_SUBTRACT_FLOATS(m_y1, m_ypos);  //(y[j] - y0)
            AVX_FLOATS m_zdiff = AVX_SUBTRACT_FLOATS(m_z1, m_zpos);  //z2[j:j+NVEC-1] - z1

            const AVX_FLOATS m_sqr_xdiff = AVX_SQUARE_FLOAT(m_xdiff);  //(x0 - x[j])^2
            const AVX_FLOATS m_sqr_ydiff = AVX_SQUARE_FLOAT(m_ydiff);  //(y0 - y[j])^2
            AVX_FLOATS r2  = AVX_ADD_FLOATS(m_sqr_xdiff, m_sqr_ydiff);
            m_zdiff = AVX_MAX_FLOATS(m_zdiff,AVX_SUBTRACT_FLOATS(m_zero,m_zdiff));//dz = fabs(dz) => dz = max(dz, -dz);
            
            AVX_FLOATS m_mask_left;
            
            //Do all the distance cuts using masks here in new scope
            {
                //the z2 arrays are sorted in increasing order. which means
                //the z2 value will increase in any future iteration of j.
                //that implies the zdiff values are also monotonically increasing
                //Therefore, if none of the zdiff values are less than pimax, then
                //no future iteration in j can produce a zdiff value less than pimax.
                AVX_FLOATS m_mask_pimax = AVX_COMPARE_FLOATS(m_zdiff,m_pimax,_CMP_LT_OS);
                if(AVX_TEST_COMPARISON(m_mask_pimax) == 0) {
                    j=N1;
                    break;
                }
                
                const AVX_FLOATS m_rpmax_mask = AVX_COMPARE_FLOATS(r2, m_sqr_rpmax, _CMP_LT_OS);
                const AVX_FLOATS m_rpmin_mask = AVX_COMPARE_FLOATS(r2, m_sqr_rpmin, _CMP_GE_OS);
                const AVX_FLOATS m_rp_mask = AVX_BITWISE_AND(m_rpmax_mask,m_rpmin_mask);
                
                //Create a combined mask by bitwise and of m1 and m_mask_left.
                //This gives us the mask for all sqr_rpmin <= r2 < sqr_rpmax
                m_mask_left = AVX_BITWISE_AND(m_mask_pimax,m_rp_mask);
                
                //If not, continue with the next iteration of j-loop
                if(AVX_TEST_COMPARISON(m_mask_left) == 0) {
                    continue;
                }
                
                //There is some r2 that satisfies sqr_rpmin <= r2 < sqr_rpmax && 0.0 <= dz^2 < pimax^2.
                r2 = AVX_BLEND_FLOATS_WITH_MASK(m_sqr_rpmax, r2, m_mask_left);
                m_zdiff = AVX_BLEND_FLOATS_WITH_MASK(m_pimax, m_zdiff, m_mask_left);
            }

            if(need_rpavg) {
                union_mDperp.m_Dperp = AVX_SQRT_FLOAT(r2);
            }
            if(need_weightavg){
                pair.dx.a = m_xdiff;
                pair.dy.a = m_ydiff;
                pair.dz.a = m_zdiff;

                union_mweight.m_weights = avx_weight_func(&pair);
            }
            
            const AVX_FLOATS m_pibin = AVX_MULTIPLY_FLOATS(m_zdiff,m_inv_dpi);
            AVX_FLOATS m_rpbin     = AVX_SET_FLOAT((DOUBLE) 0);
            //AVX_FLOATS m_all_ones  = AVX_CAST_INT_TO_FLOAT(AVX_SET_INT(-1));
            for(int kbin=nbin-1;kbin>=1;kbin--) {
                const AVX_FLOATS m_mask_low = AVX_COMPARE_FLOATS(r2,m_rupp_sqr[kbin-1],_CMP_GE_OS);
                const AVX_FLOATS m_bin_mask = AVX_BITWISE_AND(m_mask_low,m_mask_left);
                m_rpbin = AVX_BLEND_FLOATS_WITH_MASK(m_rpbin,m_kbin[kbin], m_bin_mask);
                m_mask_left = AVX_COMPARE_FLOATS(r2, m_rupp_sqr[kbin-1],_CMP_LT_OS);
                //m_mask_left = AVX_XOR_FLOATS(m_mask_low, m_all_ones);//XOR with 0xFFFF... gives the bins that are smaller than m_rupp_sqr[kbin] (and is faster than cmp_p(s/d) in theory)
                const int test = AVX_TEST_COMPARISON(m_mask_left);
                if(test==0) {
                    break;
                }
            }
            const AVX_FLOATS m_npibin_p1 = AVX_ADD_FLOATS(m_npibin,m_one);
            const AVX_FLOATS m_binproduct = AVX_ADD_FLOATS(AVX_MULTIPLY_FLOATS(m_rpbin,m_npibin_p1),m_pibin);
            union_finalbin.m_ibin = AVX_TRUNCATE_FLOAT_TO_INT(m_binproduct);

            //update the histograms
#if defined(__ICC) || defined(__INTEL_COMPILER)
#pragma unroll(AVX_NVEC)
#endif
            for(int jj=0;jj<AVX_NVEC;jj++) {
                int ibin = union_finalbin.ibin[jj];
                npairs[ibin]++;
                if(need_rpavg) {
                    rpavg[ibin] += union_mDperp.Dperp[jj];
                }
                if(need_weightavg){
                    const DOUBLE weight = union_mweight.weights[jj];
                    weightavg[ibin] += weight;
                }
            }
        }

            
        //remainder loop 
        for(;j<N1;j++){
            const DOUBLE dz = FABS(*localz1++ - zpos);
            const DOUBLE dx = *localx1++ - xpos;
            const DOUBLE dy = *localy1++ - ypos;
            for(int w = 0; w < pair.num_weights; w++){
                pair.weights1[w].d = *local_w1.weights[w]++;
            }

            if(dz >= pimax) {
                break;
            }
            
            const DOUBLE r2 = dx*dx + dy*dy;
            if(r2 >= sqr_rpmax || r2 < sqr_rpmin) {
                continue;
            }
            
            DOUBLE r, pairweight;
            if(need_rpavg) {
                r = SQRT(r2);
            }
            if(need_weightavg){
                pair.dx.d = dx;
                pair.dy.d = dy;
                pair.dz.d = dz;

                pairweight = fallback_weight_func(&pair);
            }

            int pibin = (int) (dz*inv_dpi);
            pibin = pibin > npibin ? npibin:pibin;
            for(int kbin=nbin-1;kbin>=1;kbin--) {
                if(r2 >= rupp_sqr[kbin-1]) {
                    int ibin = kbin*(npibin+1) + pibin;
                    npairs[ibin]++;
                    if(need_rpavg) {
                        rpavg[ibin] += r;
                    }
                    if(need_weightavg){
                        weightavg[ibin] += pairweight;
                    }
                    break;
                }
            }

        }//remainder loop over second set of particles
    }//loop over first set of particles

	for(int i=0;i<totnbins;i++) {
		src_npairs[i] += npairs[i];
        if(need_rpavg) {
            src_rpavg[i] += rpavg[i];
        }
        if(need_weightavg) {
            src_weightavg[i] += weightavg[i];
        }
    }

    return EXIT_SUCCESS;
}
#endif //__AVX__



#if defined (__SSE4_2__)
#include "sse_calls.h"

static inline int countpairs_rp_pi_sse_intrinsics_DOUBLE(const int64_t N0, DOUBLE *x0, DOUBLE *y0, DOUBLE *z0, const weight_struct_DOUBLE *weights0,
                                                         const int64_t N1, DOUBLE *x1, DOUBLE *y1, DOUBLE *z1, const weight_struct_DOUBLE *weights1, const int same_cell,
                                                         const DOUBLE sqr_rpmax, const DOUBLE sqr_rpmin, const int nbin, const int npibin,
                                                         const DOUBLE *rupp_sqr, const DOUBLE pimax,
                                                         const DOUBLE off_xwrap, const DOUBLE off_ywrap, const DOUBLE off_zwrap,
                                                         DOUBLE *src_rpavg, uint64_t *src_npairs,
                                                         DOUBLE *src_weightavg, const weight_method_t weight_method)
{
    if(N0 == 0 || N1 == 0) {
        return EXIT_SUCCESS;
    }

    if(src_npairs == NULL) {
        return EXIT_FAILURE;
    }
    
    const int32_t need_rpavg = src_rpavg != NULL;    
    const int32_t need_weightavg = src_weightavg != NULL;
    const int64_t totnbins = (npibin+1) * (nbin+1);
    uint64_t npairs[totnbins];
    DOUBLE rpavg[totnbins], weightavg[totnbins];
    for(int64_t i=0;i<totnbins;i++) {
        npairs[i] = 0;
        if (need_rpavg) {
            rpavg[i] = ZERO;
        }
        if(need_weightavg){
            weightavg[i] = ZERO;
        }
    }

    SSE_FLOATS m_rupp_sqr[nbin];
    for(int i=0;i<nbin;i++) {
        m_rupp_sqr[i] = SSE_SET_FLOAT(rupp_sqr[i]);
    }
    SSE_FLOATS m_kbin[nbin];
    for(int i=0;i<nbin;i++) {
        m_kbin[i] = SSE_SET_FLOAT((DOUBLE) i);
    }
    
    // A copy whose pointers we can advance
    weight_struct_DOUBLE local_w0 = {.weights={NULL}, .num_weights=0}, 
                         local_w1 = {.weights={NULL}, .num_weights=0};
    pair_struct_DOUBLE pair = {.num_weights=0};
    sse_weight_func_t_DOUBLE sse_weight_func = NULL;
    weight_func_t_DOUBLE fallback_weight_func = NULL;
    if(need_weightavg){
      // Same particle list, new copy of num_weights pointers into that list
      local_w0 = *weights0;
      local_w1 = *weights1;
      
      pair.num_weights = local_w0.num_weights;
      
      sse_weight_func = get_sse_weight_func_by_method_DOUBLE(weight_method);
      fallback_weight_func = get_weight_func_by_method_DOUBLE(weight_method);
    }

    const DOUBLE dpi = pimax/npibin;
    const DOUBLE inv_dpi = 1.0/dpi;

    int64_t prev_j = 0, n_off = 0;
    for(int64_t i=0;i<N0;i++) {
        const DOUBLE xpos = *x0++ + off_xwrap;
        const DOUBLE ypos = *y0++ + off_ywrap;
        const DOUBLE zpos = *z0++ + off_zwrap;
        for(int w = 0; w < pair.num_weights; w++){
            // local_w0.weights[w] is a pointer to a float in the particle list of weights,
            // just as x0 is a pointer into the list of x-positions.
            // The advancement of the local_w0.weights[w] pointer should always mirror x0.
            pair.weights0[w].s = SSE_SET_FLOAT(*local_w0.weights[w]++);
        }
        
        int64_t j;
        if(same_cell == 1) {
            z1++; n_off++;
            j = i+1;
        } else {
            for(;prev_j<N1;prev_j++) {
                const DOUBLE dz = *z1 - zpos;
                if(dz > -pimax) break;
                z1++; n_off++;
            }
            if(prev_j == N1) {
                i = N0;
                break;
            }
            j = prev_j;
        }
        DOUBLE *localz1 = z1;
        DOUBLE *localx1 = x1 + n_off;
        DOUBLE *localy1 = y1 + n_off;
        for(int w = 0; w < local_w1.num_weights; w++){
            local_w1.weights[w] = weights1->weights[w] + n_off;
        }
        
        for(;j<=(N1 - SSE_NVEC);j+=SSE_NVEC){

            union int4{
                SSE_INTS m_ibin;
                int ibin[SSE_NVEC];
            };
            union int4 union_finalbin;

            union float4{
                SSE_FLOATS m_Dperp;
                DOUBLE Dperp[SSE_NVEC];
            };
            union float4 union_mDperp;

            const SSE_FLOATS m_xpos = SSE_SET_FLOAT(xpos);
            const SSE_FLOATS m_ypos = SSE_SET_FLOAT(ypos);
            const SSE_FLOATS m_zpos = SSE_SET_FLOAT(zpos);
        
            const SSE_FLOATS m_x1 = SSE_LOAD_FLOATS_UNALIGNED(localx1);
            const SSE_FLOATS m_y1 = SSE_LOAD_FLOATS_UNALIGNED(localy1);
            const SSE_FLOATS m_z1 = SSE_LOAD_FLOATS_UNALIGNED(localz1);
        
            localx1 += SSE_NVEC;
            localy1 += SSE_NVEC;
            localz1 += SSE_NVEC;
            
            for(int w = 0; w < pair.num_weights; w++){
                pair.weights1[w].s = SSE_LOAD_FLOATS_UNALIGNED(local_w1.weights[w]);
                local_w1.weights[w] += SSE_NVEC;
            }

            union float4_weights{
                SSE_FLOATS m_weights;
                DOUBLE weights[SSE_NVEC];
            };
            union float4_weights union_mweight;
            
            const SSE_FLOATS m_pimax = SSE_SET_FLOAT((DOUBLE) pimax);
            const SSE_FLOATS m_sqr_rpmax = m_rupp_sqr[nbin-1];
            const SSE_FLOATS m_sqr_rpmin = m_rupp_sqr[0];
            const SSE_FLOATS m_inv_dpi    = SSE_SET_FLOAT(inv_dpi);
            const SSE_FLOATS m_zero = SSE_SET_FLOAT(ZERO);
            const SSE_FLOATS m_npibin     = SSE_SET_FLOAT((DOUBLE) npibin);
            const SSE_FLOATS m_one    = SSE_SET_FLOAT((DOUBLE) 1);
        
            const SSE_FLOATS m_xdiff = SSE_SUBTRACT_FLOATS(m_x1, m_xpos);  //(x[j] - x0)
            const SSE_FLOATS m_ydiff = SSE_SUBTRACT_FLOATS(m_y1, m_ypos);  //(y[j] - y0)
            SSE_FLOATS m_zdiff = SSE_SUBTRACT_FLOATS(m_z1, m_zpos);  //z2[j:j+NVEC-1] - z1
                
            const SSE_FLOATS m_sqr_xdiff = SSE_SQUARE_FLOAT(m_xdiff);
            const SSE_FLOATS m_sqr_ydiff = SSE_SQUARE_FLOAT(m_ydiff);
            
            SSE_FLOATS r2  = SSE_ADD_FLOATS(m_sqr_xdiff, m_sqr_ydiff);
            m_zdiff = SSE_MAX_FLOATS(m_zdiff,SSE_SUBTRACT_FLOATS(m_zero,m_zdiff));//dz = fabs(dz) => dz = max(dz, -dz);
        
            SSE_FLOATS m_mask_left;
        
            //Do all the distance cuts using masks here in new scope
            {
                //the z2 arrays are sorted in increasing order. which means
                //the z2 value will increase in any future iteration of j.
                //that implies the zdiff values are also monotonically increasing
                //Therefore, if none of the zdiff values are less than pimax, then
                //no future iteration in j can produce a zdiff value less than pimax.
                SSE_FLOATS m_mask_pimax = SSE_COMPARE_FLOATS_LT(m_zdiff,m_pimax);
                if(SSE_TEST_COMPARISON(m_mask_pimax) == 0) {
                    j=N1;
                    break;
                }
            
                const SSE_FLOATS m_rpmax_mask = SSE_COMPARE_FLOATS_LT(r2, m_sqr_rpmax);
                const SSE_FLOATS m_rpmin_mask = SSE_COMPARE_FLOATS_GE(r2, m_sqr_rpmin);
                const SSE_FLOATS m_rp_mask = SSE_BITWISE_AND(m_rpmax_mask,m_rpmin_mask);
            
                //Create a combined mask by bitwise and of m1 and m_mask_left.
                //This gives us the mask for all sqr_rpmin <= r2 < sqr_rpmax
                m_mask_left = SSE_BITWISE_AND(m_mask_pimax,m_rp_mask);
            
                //If not, continue with the next iteration of j-loop
                if(SSE_TEST_COMPARISON(m_mask_left) == 0) {
                    continue;
                }
            
                //There is some r2 that satisfies sqr_rpmin <= r2 < sqr_rpmax && 0.0 <= dz^2 < pimax^2.
                r2 = SSE_BLEND_FLOATS_WITH_MASK(m_sqr_rpmax, r2, m_mask_left);
                m_zdiff = SSE_BLEND_FLOATS_WITH_MASK(m_pimax, m_zdiff, m_mask_left);
            }
        
            if(need_rpavg) {
                union_mDperp.m_Dperp = SSE_SQRT_FLOAT(r2);
            }
            if(need_weightavg){
                pair.dx.s = m_xdiff;
                pair.dy.s = m_ydiff;
                pair.dz.s = m_zdiff;
                
                union_mweight.m_weights = sse_weight_func(&pair);
            }

            const SSE_FLOATS m_pibin = SSE_MULTIPLY_FLOATS(m_zdiff,m_inv_dpi);
            SSE_FLOATS m_rpbin     = SSE_SET_FLOAT((DOUBLE) 0);
            //SSE_FLOATS m_all_ones  = SSE_CAST_INT_TO_FLOAT(SSE_SET_INT(-1));
            for(int kbin=nbin-1;kbin>=1;kbin--) {
                const SSE_FLOATS m_mask_low = SSE_COMPARE_FLOATS_GE(r2,m_rupp_sqr[kbin-1]);
                const SSE_FLOATS m_bin_mask = SSE_BITWISE_AND(m_mask_low,m_mask_left);
                m_rpbin = SSE_BLEND_FLOATS_WITH_MASK(m_rpbin,m_kbin[kbin], m_bin_mask);
                m_mask_left = SSE_COMPARE_FLOATS_LT(r2, m_rupp_sqr[kbin-1]);
                //XOR with 0xFFFF... gives the bins that are smaller than m_rupp_sqr[kbin] (and is faster than cmp_p(s/d) in theory)
                //m_mask_left = SSE_XOR_FLOATS(m_mask_low, m_all_ones);
                const int test = SSE_TEST_COMPARISON(m_mask_left);
                if(test==0) {
                    break;
                }
            }
            const SSE_FLOATS m_npibin_p1 = SSE_ADD_FLOATS(m_npibin,m_one);
            const SSE_FLOATS m_binproduct = SSE_ADD_FLOATS(SSE_MULTIPLY_FLOATS(m_rpbin,m_npibin_p1),m_pibin);
            union_finalbin.m_ibin = SSE_TRUNCATE_FLOAT_TO_INT(m_binproduct);

            //update the histograms
#if defined(__ICC) || defined(__INTEL_COMPILER)
#pragma unroll(SSE_NVEC)
#endif
            for(int jj=0;jj<SSE_NVEC;jj++) {
                int ibin = union_finalbin.ibin[jj];
                npairs[ibin]++;
                if(need_rpavg) {
                    rpavg[ibin] += union_mDperp.Dperp[jj];
                }
                if(need_weightavg){
                    const DOUBLE weight = union_mweight.weights[jj];
                    weightavg[ibin] += weight;
                }
            }
        }
    
    
        for(;j<N1;j++) {
            const DOUBLE dx = *localx1++ - xpos;
            const DOUBLE dy = *localy1++ - ypos;
            const DOUBLE dz = FABS(*localz1++ - zpos);
            for(int w = 0; w < pair.num_weights; w++){
                pair.weights1[w].d = *local_w1.weights[w]++;
            }

            if(dz >= pimax) break;
        
            const DOUBLE r2 = dx*dx + dy*dy;
            if(r2 >= sqr_rpmax || r2 < sqr_rpmin) continue;
            
            DOUBLE r, pairweight;
            if(need_rpavg) {
                r = SQRT(r2);
            }
            if(need_weightavg){
                pair.dx.d = dx;
                pair.dy.d = dy;
                pair.dz.d = dz;

                pairweight = fallback_weight_func(&pair);
            }

            int pibin = (int) (dz*inv_dpi);
            pibin = pibin > npibin ? npibin:pibin;
            for(int kbin=nbin-1;kbin>=1;kbin--){
                if(r2 >= rupp_sqr[kbin-1]) {
                    int ibin = kbin*(npibin+1) + pibin;
                    npairs[ibin]++;
                    if(need_rpavg) {
                        rpavg[ibin] += r;
                    }
                    if(need_weightavg){
                        weightavg[ibin] += pairweight;
                    }
                    break;
                }
            }//searching for kbin loop
        }
    }
  
    for(int i=0;i<totnbins;i++) {
        src_npairs[i] += npairs[i];
        if(need_rpavg) {
            src_rpavg[i] += rpavg[i];
        }
        if(need_weightavg) {
            src_weightavg[i] += weightavg[i];
        }
    }

    return EXIT_SUCCESS;
}
#endif //__SSE4_2__


static inline int countpairs_rp_pi_fallback_DOUBLE(const int64_t N0, DOUBLE *x0, DOUBLE *y0, DOUBLE *z0, const weight_struct_DOUBLE *weights0,
                                                   const int64_t N1, DOUBLE *x1, DOUBLE *y1, DOUBLE *z1, const weight_struct_DOUBLE *weights1,
                                                   const int same_cell,
                                                   const DOUBLE sqr_rpmax, const DOUBLE sqr_rpmin, const int nbin, const int npibin,
                                                   const DOUBLE *rupp_sqr, const DOUBLE pimax,
                                                   const DOUBLE off_xwrap, const DOUBLE off_ywrap, const DOUBLE off_zwrap,
                                                   DOUBLE *src_rpavg, uint64_t *src_npairs,
                                                   DOUBLE *src_weightavg, const weight_method_t weight_method)
{

    if(N0 == 0 || N1 == 0) {
        return EXIT_SUCCESS;
    }

    if(src_npairs == NULL) {
        return EXIT_FAILURE;
    }

    /*----------------- FALLBACK CODE --------------------*/
    const int32_t need_rpavg = src_rpavg != NULL;
    const int32_t need_weightavg = src_weightavg != NULL;
    const int64_t totnbins = (npibin+1)*(nbin+1);
    uint64_t npairs[totnbins];
    DOUBLE rpavg[totnbins], weightavg[totnbins];
    for(int i=0;i<totnbins;i++) {
        npairs[i] = 0;
        if(need_rpavg) {
            rpavg[i]=ZERO;
        }
        if(need_weightavg){
            weightavg[i]=ZERO;
        }
    }
    
    // A copy whose pointers we can advance
    weight_struct_DOUBLE local_w0 = {.weights={NULL}, .num_weights=0}, 
                         local_w1 = {.weights={NULL}, .num_weights=0};
    pair_struct_DOUBLE pair = {.num_weights=0};
    weight_func_t_DOUBLE weight_func = NULL;
    if(need_weightavg){
        // Same particle list, new copy of num_weights pointers into that list
        local_w0 = *weights0;
        local_w1 = *weights1;

        pair.num_weights = local_w0.num_weights;

        weight_func = get_weight_func_by_method_DOUBLE(weight_method);
    }


    const DOUBLE dpi = pimax/npibin;
    const DOUBLE inv_dpi = 1.0/dpi;


    /* naive implementation that is guaranteed to compile */
    int64_t nleft=N1, n_off = 0;
    for(int64_t i=0;i<N0;i++) {
        const DOUBLE xpos = *x0++ + off_xwrap;
        const DOUBLE ypos = *y0++ + off_ywrap;
        const DOUBLE zpos = *z0++ + off_zwrap;
        for(int w = 0; w < pair.num_weights; w++){
            pair.weights0[w].d = *local_w0.weights[w]++;
        }

        /* If in the same cell, unique pairs are guaranteed by not including the current particle */
        if(same_cell == 1) {
            z1++; n_off++;
            nleft--;
        } else {
            /* For a different cell, all pairs are unique pairs, since two cells are only opened for pairs once (accounted for in the assign_ngb_cells function)*/
            while(nleft > 0) {
                /*Particles are sorted on 'z', in increasing order */
                const DOUBLE dz = *z1 - zpos;
                if(dz > -pimax) break;
                z1++; n_off++;
                nleft--;
            }
            /*If no particle in the second cell satisfies distance constraints on 'dz' for the current 'i'th particle in first cell, 
              then there can be no more pairs from any particles in the first cell (since the first cell is also sorted in increasing order in 'z')
             */
            if(nleft == 0) {
                i=N0;
                break;
            }
        }
        DOUBLE *localz1 = z1;
        DOUBLE *localx1 = x1 + n_off;
        DOUBLE *localy1 = y1 + n_off;
        for(int w = 0; w < pair.num_weights; w++){
            local_w1.weights[w] = weights1->weights[w] + n_off;
        }

        for(int64_t j=0;j<nleft;j++) {
            const DOUBLE dx = *localx1++ - xpos;
            const DOUBLE dy = *localy1++ - ypos;
            const DOUBLE dz = FABS((*localz1++ - zpos));
            for(int w = 0; w < pair.num_weights; w++){
                pair.weights1[w].d = *local_w1.weights[w]++;
            }

            if(dz >= pimax) break;
            
            const DOUBLE r2 = dx*dx + dy*dy ;
            if(r2 >= sqr_rpmax || r2 < sqr_rpmin) continue;

            if(need_weightavg){
                pair.dx.d = dx;
                pair.dy.d = dy;
                pair.dz.d = dz;
            }

            DOUBLE r, pairweight;
            if(need_rpavg) {
                r = SQRT(r2);
            }
            if(need_weightavg){
                pairweight = weight_func(&pair);
            }

            int pibin = (int) (dz*inv_dpi);
            pibin = pibin > npibin ? npibin:pibin;
            for(int kbin=nbin-1;kbin>=1;kbin--) {
                if(r2 >= rupp_sqr[kbin-1]) {
                    const int ibin = kbin*(npibin+1) + pibin;
                    npairs[ibin]++;
                    if(need_rpavg) {
                        rpavg[ibin]+=r;
                    }
                    if(need_weightavg){
                        weightavg[ibin] += pairweight;
                    }
                    break;
                }
            }
        }
    }
    for(int i=0;i<totnbins;i++) {
        src_npairs[i] += npairs[i];
        if(need_rpavg) {
            src_rpavg[i] += rpavg[i];
        }
        if(need_weightavg){
            src_weightavg[i] += weightavg[i];
        }
    }
   /*----------------- FALLBACK CODE --------------------*/
    return EXIT_SUCCESS;
}
